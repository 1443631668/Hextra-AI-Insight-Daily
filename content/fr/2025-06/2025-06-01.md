---
title: 06-01-Daily
weight: 30
breadcrumbs: false
comments: true
description: R√©cemment, l'√©quipe d'intelligence du langage naturel du Tongyi Lab a
  d√©voil√© et rendu open source VRAG-RL ‚Äì un framework d'inf√©rence RAG multimodal √†
  perception visuelle. Son but ? R√©gler le casse-t√™te de l'IA quand il s'agit de r√©cup√©rer
  des infos cl√©s et de faire de l'inf√©rence fine √† partir d...
---
# Infos IA du 1er juin 2025

1.  R√©cemment, l'√©quipe d'intelligence du langage naturel du **Tongyi Lab** a **d√©voil√© et rendu open source VRAG-RL** ‚Äì un **framework d'inf√©rence RAG multimodal √† perception visuelle**. Son but ? R√©gler le casse-t√™te de l'**IA** quand il s'agit de r√©cup√©rer des infos cl√©s et de faire de l'**inf√©rence fine** √† partir de **langages visuels** comme des images ou des tableaux. Ses m√©canismes d'apprentissage par renforcement et de perception visuelle innovants ont vachement am√©lior√© la compr√©hension et l'efficacit√© de la r√©cup√©ration d'infos visuelles. Ce framework a **cartonn√©** sur plusieurs datasets de r√©f√©rence et pourrait bien, √† l'avenir, doper la **capacit√© de g√©n√©ralisation** des mod√®les pour diverses t√¢ches visuelles. Pour en savoir plus, jette un ≈ìil [ici](https://github.com/Alibaba-NLP/VRAG).
2.  Un groupe de chercheurs de l'Arizona State University a **publi√© une √©tude** soulignant que les **grands mod√®les de langage** ne font pas de **vraie inf√©rence** ; ils se contentent de **chercher des corr√©lations entre les donn√©es**. √áa pourrait mener √† des **malentendus** du public sur leur fonctionnement. L'√©tude insiste : √† l'heure o√π on d√©pend de plus en plus de l'**IA**, il faut qu'on **soit plus vigilants** quant aux capacit√©s technologiques. La **recherche en IA** devrait, √† l'avenir, s'orienter vers des mod√®les plus **explicables**.
3.  **Perplexity AI** a **officiellement lanc√© Perplexity Labs**, offrant aux abonn√©s Pro un **nouvel outil de productivit√© IA** qui permet la **collaboration multi-outils**. Il peut simplifier des processus de d√©veloppement de projets complexes en quelques minutes, avec pour objectif d'offrir un **support de A √† Z**, de l'id√©e au r√©sultat. Cette fonctionnalit√©, avec des **capacit√©s cl√©s** comme la navigation web approfondie et l'ex√©cution de code, marque la **transformation** de Perplexity, passant d'un moteur de r√©ponses √† une **plateforme de production IA compl√®te**.
4.  **Quark** a **r√©cemment mis en ligne sa fonctionnalit√© "Recherche Approfondie"**. Bas√©e sur le **grand mod√®le Tongyi Qianwen**, elle peut automatiser tout le processus de recherche, de la collecte de donn√©es √† la **g√©n√©ration de rapports**, pour des sujets complexes comme des travaux acad√©miques ou des analyses sectorielles. Cette initiative marque un nouveau saut de l'**IA**, qui passe d'un **outil de recherche d'informations** √† un **partenaire de cr√©ation de contenu**, offrant un **soutien super efficace** pour la recherche scientifique, l'analyse de march√©, et bien d'autres cas d'usage.
5.  **Alibaba Cloud** a **officiellement lanc√© Tongyi Lingma AI IDE**, un environnement de d√©veloppement d'intelligence artificielle natif. Gr√¢ce √† ses puissantes fonctionnalit√©s de **mode agent de programmation**, de **m√©moire √† long terme** et de **pr√©diction de suggestions in-line**, il booste clairement l'**efficacit√© de programmation** des d√©veloppeurs. Ce produit est d√©j√† **disponible en t√©l√©chargement gratuit**, et ses plugins ont g√©n√©r√© plus de 3 milliards de lignes de code cumul√©es, en faisant un outil d'assistance √† la programmation super populaire qui offre un **gros coup de pouce** pour le d√©veloppement en entreprise.
6.  **Memvid** est un **outil de m√©moire IA super innovant**. En **encodant des donn√©es textuelles en vid√©os MP4**, il permet une **recherche s√©mantique ultra-rapide en moins d'une seconde**, √©conomisant un max d'espace de stockage et supportant l'utilisation hors ligne. Il a une **fonction chat int√©gr√©e**, supporte l'**importation de documents PDF**, et offre des **possibilit√©s in√©dites et r√©volutionnaires** pour des domaines comme la **gestion efficace des connaissances** et la **recherche acad√©mique**. Pour en savoir plus, jette un ≈ìil [ici](https://github.com/Olow304/memvid).
7.  Dario Amodei, le PDG d'Anthropic, a **mis en garde** : l'**IA** pourrait, dans les cinq prochaines ann√©es, **remplacer la moiti√© des postes de cols blancs d'entr√©e de gamme**, ce qui entra√Ænerait une **flamb√©e du ch√¥mage** √† 10-20% et **accentuerait les in√©galit√©s √©conomiques**. Il a appel√© √† une meilleure **sensibilisation** du public au d√©veloppement de l'**IA** et √† une meilleure **litt√©ratie en IA**, afin que les gens puissent s'adapter au futur environnement professionnel. Il a aussi insist√© sur le fait que les d√©cideurs politiques doivent cogiter sur des **solutions** pour une √©conomie super intelligente.
8.  La startup IA **Manus** a **lanc√© en grande pompe sa fonctionnalit√© Manus Slides**. Il suffit d'un prompt pour **g√©n√©rer en un clic des diapos pro**, couvrant divers sc√©narios comme les r√©unions d'affaires ou les cours √©ducatifs, ce qui **booste consid√©rablement l'efficacit√© de cr√©ation de pr√©sentations**. Gr√¢ce √† sa **g√©n√©ration intelligente** et son **√©dition flexible**, cette fonction permet d'exporter au format PowerPoint ou PDF, marquant ainsi un pas en avant des **agents IA**, qui √©voluent de l'automatisation des t√¢ches vers des **outils de productivit√©**.
9.  Avec **7086 √©toiles** sur GitHub, **prompt-eng-interactive-tutorial** est le projet open source du **tutoriel interactif d'ing√©nierie de prompts** d'Anthropic. Il vise √† aider les utilisateurs √† **apprendre l'ing√©nierie de prompts de mani√®re ludique et efficace**. Pour plus de d√©tails, va voir [ici](https://github.com/anthropics/prompt-eng-interactive-tutorial).
10. Le projet **onlook**, qui a d√©croch√© **10143 √©toiles**, est un **√©diteur de code visuel open source ax√© sur l'ambiance**. Il utilise l'**IA** pour aider designers et d√©veloppeurs √† **construire, embellir et √©diter visuellement des applications React**. Cet outil, c'est comme le **curseur** d'un designer, rendant le **d√©veloppement React** plus **intuitif et efficace**. Pour plus d'infos, c'est par [l√†](https://github.com/onlook-dev/onlook).
11. Le projet **anthropic-cookbook**, avec **12755 √©toiles**, est une **collection de notebooks/recettes** d'Anthropic qui **montre comment utiliser Claude de mani√®re ludique et efficace**. Il offre aux utilisateurs une panoplie de **fa√ßons d'utiliser Claude**, et c'est un [lien pratique](https://github.com/anthropics/anthropic-cookbook) pour **apprendre et appliquer Claude**.
12. **MMSI-Bench** est un **benchmark VQA** pour l'**intelligence spatiale multi-images**. L'√©tude a r√©v√©l√© que, m√™me si les grands mod√®les de langage multimodaux (MLLM) ont progress√©, il y a un **foss√© √©norme** entre leur pr√©cision (30-40%) et celle des humains (97%) quand il s'agit de **raisonnement spatial multi-images**. Cette recherche a identifi√© quatre modes d'√©chec principaux pour les mod√®les, et offre des **pistes pr√©cieuses** pour booster l'**intelligence spatiale multi-images** √† l'avenir. Pour les d√©tails de l'√©tude, c'est par [ici](https://arxiv.org/abs/2505.23764).
13. **ZeroGUI** est un **framework d'apprentissage en ligne super innovant**. Il automatise l'**entra√Ænement des agents GUI avec z√©ro co√ªt humain**, et, gr√¢ce √† la g√©n√©ration automatique de t√¢ches et √† l'√©valuation des r√©compenses bas√©es sur VLM, il g√®re la **forte d√©pendance** de l'apprentissage GUI traditionnel √† l'annotation manuelle. Les tests ont montr√© que ce framework am√©liore consid√©rablement les **performances des agents GUI** dans divers environnements, et il apporte une **solution hyper efficace** pour l'**automatisation des op√©rations GUI**. Pour les d√©tails de l'√©tude, c'est par [l√†](https://arxiv.org/abs/2505.23762).
14. **ATLAS** est un module de m√©moire √† long terme haute capacit√© con√ßu pour les architectures **Transformer**. Il surmonte les limites des mod√®les actuels en **compr√©hension de longues s√©quences** en optimisant le **contexte de m√©moire**, et apprend ainsi la meilleure strat√©gie de m√©moire au moment du test. Les r√©sultats des tests montrent qu'**ATLAS** surpasse les mod√®les Transformer et r√©currents lin√©aires dans des t√¢ches comme la mod√©lisation linguistique et la compr√©hension de longs contextes, **boostant significativement les performances**. Pour les d√©tails de l'√©tude, c'est par [ici](https://arxiv.org/abs/2505.23735).

---

#### **√âcoute la version audio**

| üéôÔ∏è **Â∞èÂÆáÂÆô** | üìπ **ÊäñÈü≥** |
| --- | --- |
| [Êù•ÁîüÂ∞èÈÖíÈ¶Ü](https://www.xiaoyuzhoufm.com/podcast/683c62b7c1ca9cf575a5030e)  |   [Êù•ÁîüÊÉÖÊä•Á´ô](https://www.douyin.com/user/MS4wLjABAAAAwpwqPQlu38sO38VyWgw9ZjDEnN4bMR5j8x111UxpseHR9DpB6-CveI5KRXOWuFwG)|
| ![Â∞èÈÖíÈ¶Ü](https://s1.imagehub.cc/images/2025/06/24/f959f7984e9163fc50d3941d79a7f262.md.png) | ![ÊÉÖÊä•Á´ô](https://s1.imagehub.cc/images/2025/06/24/7fc30805eeb831e1e2baa3a240683ca3.md.png) |